{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出数据并分层\n",
    "def extract_and_split(df, district_name):\n",
    "    if district_name != 'national':\n",
    "        # 县级PAC\n",
    "        provs_set = District_dic[district_name]\n",
    "        provs_id = set(Prov_shp['省代码'][[prov in provs_set for prov in Prov_shp['省']]])\n",
    "        # print(provs_id)\n",
    "        county_lst = County_shp['PAC'][[id in provs_id for id in County_shp['省代码']]]\n",
    "        # print(len(county_lst))\n",
    "        \n",
    "        # 提取数据\n",
    "        district_id = pd.DataFrame({'PAC': county_lst})\n",
    "        district_df = pd.merge(df, district_id, how = 'right')\n",
    "    else:\n",
    "        district_df = df\n",
    "    \n",
    "    # 0: high, 1: medium, 2: low\n",
    "    district_df0 = district_df[district_df['light'] > Edges[1]]\n",
    "    district_df1 = district_df[[Edges[0] < lit <= Edges[1] for lit in district_df['light']]]\n",
    "    district_df2 = district_df[district_df['light'] <= Edges[0]]\n",
    "    \n",
    "    # 每类图片数量\n",
    "    print('high: {}, medium: {}, low: {}, total: {}'.format(len(district_df0), len(district_df1), len(district_df2), len(district_df)))\n",
    "    \n",
    "    return district_df0, district_df1, district_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分层聚类函数\n",
    "def cls_cluster(district_df_lst, cluster_nums):\n",
    "    cls_df_lst = []\n",
    "    for i in range(3):\n",
    "        district_df = district_df_lst[i]\n",
    "        num = cluster_nums[i]\n",
    "        \n",
    "        km = KMeans(n_clusters = num, random_state = 42)\n",
    "        labels = km.fit_predict(district_df.iloc[:, 0:125])\n",
    "        if i > 0:\n",
    "            labels = labels + np.cumsum(cluster_nums)[i-1]\n",
    "        district_df['cluster_id'] = labels\n",
    "        \n",
    "        cls_df_lst.append(district_df)\n",
    "        \n",
    "    district_total = pd.concat(cls_df_lst)\n",
    "    \n",
    "    cls_count = pd.value_counts(district_total.cluster_id)\n",
    "    plt.hist(cls_count, bins = 6)  \n",
    "    plt.show()\n",
    "    \n",
    "    return district_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate histogram\n",
    "def generate_hist(df, cluster_num, PAC = None):\n",
    "    \"\"\"\n",
    "    df.columns: [image_name (image_id), cluster_id, PAC, ...]\n",
    "    \"\"\"\n",
    "    if PAC is None:\n",
    "        PAC = np.unique(df.PAC)\n",
    "        \n",
    "    hist_data = []\n",
    "    for pac in PAC:\n",
    "        cur_hist = []\n",
    "        for i in range(cluster_num):\n",
    "            cur_hist.append(sum(df.cluster_id[df.PAC == pac] == i))\n",
    "        \n",
    "        hist_data.append(cur_hist)\n",
    "        \n",
    "    hist_data = pd.DataFrame(hist_data)\n",
    "    hist_data.columns = [str(i) for i in range(cluster_num)]\n",
    "    hist_data['PAC'] = PAC\n",
    "        \n",
    "    return hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate hist\n",
    "def generate_grid(df):\n",
    "    \"\"\"\n",
    "    df: [image_name (name), cluster_id]\n",
    "    \"\"\"\n",
    "    suffix = r'-2017\\.png'\n",
    "    \n",
    "    grid_df = df.loc[:, ['name', 'cluster_id']].sort_values(by = 'cluster_id')\n",
    "    \n",
    "    # 去掉后缀\n",
    "    y_x = [re.sub(suffix, '', name) for name in grid_df.name]\n",
    "    grid_df['name'] = y_x\n",
    "    \n",
    "    # 改名\n",
    "    grid_df.columns = ['y-x', 'cluster_id']\n",
    "    \n",
    "    return grid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readin Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric Features and Image Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入原始数据\n",
    "data = pd.read_csv('Data/2017_features.csv')\n",
    "data = data.dropna()\n",
    "#data = data[data['features']!='adsadas']\n",
    "name_night = pd.read_csv('Data/2017Name_lights.csv')\n",
    "label = pd.read_csv('Data/PAC_GDP17.csv')\n",
    "data = pd.merge(data, name_night, how ='left')\n",
    "data = pd.merge(data, label.loc[:, ['PAC', 'GDP']], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontstr = 'Image/2017/'\n",
    "# 处理原始数据\n",
    "X = []  # 4096维向量\n",
    "Name = [] # 图片名\n",
    "Light = [] # 灯光强度\n",
    "y = []  # GDP\n",
    "PAC = []  # 标识\n",
    "for i in data.index:\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    # if i >= 100:\n",
    "    #     break\n",
    "    \n",
    "    #try:\n",
    "    # 4096维向量\n",
    "    x_i = [float(x) for x in re.split(r', |\\[|\\]', data['features'].loc[i]) if len(x) > 0]\n",
    "    x_i = np.array(x_i).reshape(-1, 4096)  # 4096维向量\n",
    "    X.append(x_i)\n",
    "    # 灯光强度与图片名称\n",
    "    str_lst = [s for s in re.split(r', |\\[|\\]|\\(|\\)', re.sub(\"'\", '',data['Name'].loc[i])) if len(s) > 0] \n",
    "    name_i = [(str_lst[2*i]).replace(frontstr, '') for i in range(len(str_lst)//2)] # 偶数索引\n",
    "    light_i = [float(str_lst[2*i+1]) for i in range(len(str_lst)//2)]  # 基数索引\n",
    "    Name.append(name_i)\n",
    "    Light.append(light_i)\n",
    "    # GDP\n",
    "    y.append(data['GDP'].loc[i])\n",
    "    # PAC\n",
    "    PAC.append(data['PAC'].loc[i])\n",
    "    #except:\n",
    "       # print('error')\n",
    "\n",
    "# 去空\n",
    "zeros = [X.index(x) for x in X if x.shape[0] == 0]\n",
    "X = np.delete(np.array(X), zeros)\n",
    "Name = np.delete(np.array(Name), zeros)\n",
    "Light = np.delete(np.array(Light), zeros)\n",
    "y = np.delete(np.array(y), zeros)\n",
    "PAC = np.delete(np.array(PAC), zeros)\n",
    "# 直接排列所有4096维向量，图片名，与灯光强度\n",
    "X_ = np.concatenate(X)\n",
    "Name_ = np.concatenate(Name)\n",
    "Light_ = np.concatenate(Light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片编号与PAC编号对应\n",
    "img_nums = [len(county) for county in X]\n",
    "img2county = []\n",
    "for i, num in enumerate(img_nums):\n",
    "    cur_array = [i]*num\n",
    "    img2county.append(cur_array)\n",
    "img2county = np.concatenate(img2county)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geographic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地理信息\n",
    "County_shp = geopandas.GeoDataFrame.from_file('Data/county/县级行政区.shp')\n",
    "Prov_shp = geopandas.GeoDataFrame.from_file('Data/prov/省级行政区.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地区字典\n",
    "District_dic = {\n",
    "    'east': set(['山东省', '江苏省', '浙江省', '安徽省', '江西省', '福建省', '上海市']),\n",
    "    'south': set(['广东省', '广西壮族自治区', '海南省', '香港特别行政区', '澳门特别行政区']),\n",
    "    'north': set(['山西省', '河北省', '北京市', '天津市', '内蒙古自治区']),\n",
    "    'mid': set(['湖北省', '河南省', '湖南省']),\n",
    "    'northwest': set(['青海省', '宁夏回族自治区', '陕西省', '甘肃省', '新疆维吾尔自治区']),\n",
    "    'southwest': set(['贵州省', '云南省', '重庆市', '四川省', '西藏自治区']),\n",
    "    'northeast': set(['吉林省', '黑龙江省', '辽宁省']) \n",
    "}\n",
    "# 分类光强\n",
    "Edges = [0.02, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensional Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不做标准化处理\n",
    "pca = PCA(n_components = 0.80) \n",
    "pca.fit(X_)\n",
    "reduced_X = pca.transform(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X.shape  # (254637, 125) in our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_df = pd.DataFrame(reduced_X)\n",
    "km_df['cluster_id'] = np.repeat(0, reduced_X.shape[0])\n",
    "km_df['name'] = Name_\n",
    "km_df['light'] = Light_\n",
    "km_df['PAC'] = PAC[img2county]\n",
    "km_df.to_csv('Data/km/Data2017_PCA80_KMeans.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## National"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出数据\n",
    "national_df_lst = extract_and_split(km_df, 'national')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### straitified KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_nums = [5, 25, 60] # self-identified according to experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类聚类\n",
    "national_df = cls_cluster(national_df_lst, national_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_df.to_csv('Data/km/Data2017_national_PCA80_KMeans90_straitified.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect with siScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对标siScore\n",
    "national_hist = generate_hist(national_df, sum(national_nums))\n",
    "national_grid = generate_grid(national_df)\n",
    "national_hist.to_csv('Data/hist/hist2017_national_PCA80_KMeans90_straitified.csv', index = False, header = True)\n",
    "national_grid.to_csv('Data/grid/grid2017_national_PCA80_KMeans90_straitified.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_lst_dic = {} \n",
    "for name in list(District_dic.keys()):\n",
    "    print('======={}======'.format(name))\n",
    "    district_lst_dic[name] = df_lst = extract_and_split(km_df, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Repeat the process of straitified Kmeans, hist, and grid for each district, respectively"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
